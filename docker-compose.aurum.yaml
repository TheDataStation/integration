# For a simple Aurum setup, install Docker Compose
# <https://docs.docker.com/compose/install/> and run these commands:
#
# 1. docker-compose up -d elasticsearch
#     Brings up an elasticsearch instance using the data located at data/elasticsearch. This data persists even if you destroy and recreate the elasticsearch Docker container.
# 2*. docker-compose build profiler
# 2. docker-compose up profiler
#     Runs the ddprofiler with the CSVs located in data/csvs. Writes to the above elasticsearch container.
# 3*. docker-compose build nbc
# 3*. docker-compose run --rm -T nbc
# 3. docker-compose up -d neodb
#    Run the neo4j instance,user='neo4j',password='aurum'
# 4. docker-compose up nbc
#     Runs networkbuildercoordinator.py with the above elasticsearch and saves its files to data/pickles.
# 5. docker-compose up notebook
#     Runs a Jupyter notebook with Aurum libraries and the above pickles from data/pickles.
# 6. docker-compose up frontend
#     Runs the web frontend and API on http://localhost:3000 and http://localhost:5000 respectively. Uses pickles from data/pickles.

version: '3'

networks:
  aurum_net:
    driver: bridge

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.0.1
    volumes:
      - ./data/elasticsearch:/usr/share/elasticsearch/data
      # I get permission problems with this mount: it is owned by root when
      # initially created; but elasticsearch is running (probably) as a
      # regular unix user. I chmoded the directory to see if that fixes it
      # but that's not a nice fix.
      # I also get this error as elasticsearch starts:
      # [1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
      # which doesn't happen in my manually installed elasticsearch in
      # integration/ docker container
      # It looks like that is a property of my host env, not of the docker
      # env - unclear why it doesn't happen for manual launches.
      # To reconfigure my host env:
      # sysctl -w vm.max_map_count=262144
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      aurum_net:
        aliases:
          - elasticsearch

  profiler:
    depends_on:
      - elasticsearch
    image: aurum/ddprofiler:0.1
    build:
      context: ../ddprofiler
      dockerfile: ../ddprofiler/Dockerfile
    volumes:
      - ./data:/data
    command: " --store.server elasticsearch --sources /data/adventureWork.yaml"  # "<profiler args here>"
    # this /data/mitdwhdata.yml file doesn't exist in the repo and was externally provided.
    # more recent work has been using eg. adventureWorks and zip codes, so those files
    # should be provided instead - and is there a way to make this be done automatically
    # in the context of docker-context, or a wrapper?
    networks:
      aurum_net:
        aliases:
          - profiler

  # TODO: why is this different from the above profiler commmand?
  # profiler is also a one-off command so probably shouldn't run as a service
  # but be run as one-off like the nbc example.
  nbc:
    depends_on:
      - elasticsearch
    image: aurum/networkbuildercoordinator:0.1
    build:
      context: ../nbc
      dockerfile: Dockerfile
    volumes:
      - ./data:/data
      - ./data/models:/output
    networks:
      aurum_net:
        aliases:
          - nbc

  notebook:
    depends_on:
      - elasticsearch
    image: aurum/notebook
    build:
      context: .
      dockerfile: docker/Dockerfile-jupyter-notebook
    volumes:
      - ./data/models:/data/models
    ports:
      - 8888:8888
    networks:
      aurum_net:
        aliases:
          - notebook

#  frontend:
#    depends_on:
#      - elasticsearch
#    image: aurum/frontend
#    build:
#      context: .
#      dockerfile: docker/Dockerfile-ui
#    volumes:
#      - ./data/models:/aurum/data/models
#    ports:
#      - 3000:3000
#      - 5000:5000
#    networks:
#      aurum_net:
#        aliases:
#          - frontend


